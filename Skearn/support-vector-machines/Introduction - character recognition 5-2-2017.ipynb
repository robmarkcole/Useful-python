{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/tutorial/basic/tutorial.html\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html#sphx-glr-auto-examples-classification-plot-digits-classification-py\n",
    "\n",
    "Salient points - all data presented to classified as 2d array of samples vs features. Flatten 2 image to 1d array and call them features. Split data into test and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image0 = digits.images[0]    # a single digit image\n",
    "#images are ndarray\n",
    "image0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_and_labels = list(zip(digits.images, digits.target))  # target is the classification label\n",
    "len(images_and_labels)  # how many images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "        [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "        [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "        [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "        [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "        [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "        [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "        [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]]), 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_and_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for index, (image, label) in enumerate(images_and_labels[:4]):    # plot first 4 images and their label\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = len(digits.images)\n",
    "n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = digits.images.reshape((n_samples, -1))      # flatten the image using np.reshape\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a classifier: a support vector classifier\n",
    "classifier = svm.SVC(gamma=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = data[:round(n_samples / 2)]\n",
    "test_data_labels = digits.target[:round(n_samples / 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We learn the digits on the first half of the digits\n",
    "classifier.fit(test_data, test_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99        88\n",
      "          1       0.99      0.97      0.98        91\n",
      "          2       0.99      0.99      0.99        86\n",
      "          3       0.98      0.87      0.92        91\n",
      "          4       0.99      0.96      0.97        92\n",
      "          5       0.95      0.97      0.96        91\n",
      "          6       0.99      0.99      0.99        91\n",
      "          7       0.96      0.99      0.97        89\n",
      "          8       0.94      1.00      0.97        88\n",
      "          9       0.93      0.98      0.95        92\n",
      "\n",
      "avg / total       0.97      0.97      0.97       899\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[87  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 88  1  0  0  0  0  0  1  1]\n",
      " [ 0  0 85  1  0  0  0  0  0  0]\n",
      " [ 0  0  0 79  0  3  0  4  5  0]\n",
      " [ 0  0  0  0 88  0  0  0  0  4]\n",
      " [ 0  0  0  0  0 88  1  0  0  2]\n",
      " [ 0  1  0  0  0  0 90  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 88  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 88  0]\n",
      " [ 0  0  0  1  0  1  0  0  0 90]]\n"
     ]
    }
   ],
   "source": [
    "# Now predict the value of the digit on the second half:\n",
    "expected = digits.target[round(n_samples / 2):]                # labels of the second half of the data\n",
    "predicted = classifier.predict(data[round(n_samples / 2):])    # run the classifier\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_and_predictions = list(zip(digits.images[round(n_samples / 2):], predicted))\n",
    "for index, (image, prediction) in enumerate(images_and_predictions[:4]):\n",
    "    plt.subplot(2, 4, index + 5)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Prediction: %i' % prediction)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classifier.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(classifier, 'classifier.pkl')     # save the classifier as a pickle object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introduction - character recognition 5-2-2017.ipynb\n",
      "README.md\n",
      "classifier.pkl\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
