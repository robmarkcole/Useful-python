{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Masked Normalized Cross-Correlation\n\n\nIn this example, we use the masked normalized cross-correlation to identify the relative shift\nbetween two similar images containing invalid data.\n\nIn this case, the images cannot simply be masked before computing the cross-correlation, \nas the masks will influence the computation. The influence of the masks must be removed from\nthe cross-correlation, as is described in [1]_.\n\nIn this example, we register the translation between two images. However, one of the \nimages has about 25% of the pixels which are corrupted.\n\n.. [1] D. Padfield, \"Masked object registration in the Fourier domain\" \n       IEEE Transactions on Image Processing (2012). :DOI:`10.1109/TIP.2011.2181402`\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom skimage import data, draw\nfrom skimage.feature import masked_register_translation\nfrom scipy import ndimage as ndi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define areas of the image which are invalid.\nProbability of an invalid pixel is 25%.\nThis could be due to a faulty detector, or edges that\nare not affected by translation (e.g. moving object in a window).\nSee reference paper for more examples\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "image = data.camera()\nshift = (-22, 13)\n\ncorrupted_pixels = np.random.choice([False, True], \n                                    size = image.shape, \n                                    p = [0.25, 0.75])\n\n# The shift corresponds to the pixel offset relative to the reference image\noffset_image = ndi.shift(image, shift)\noffset_image *= corrupted_pixels\nprint(\"Known offset (row, col): {}\".format(shift))\n\n# Determine what the mask is based on which pixels are invalid\n# In this case, we know what the mask should be since we corrupted \n# the pixels ourselves\nmask = corrupted_pixels\n\ndetected_shift = masked_register_translation(image, offset_image, mask)\n\nprint(\"Detected pixel offset (row, col): {}\".format(-detected_shift))\n\nfig = plt.figure(figsize=(8, 3))\nax1 = plt.subplot(1, 3, 1)\nax2 = plt.subplot(1, 3, 2, sharex=ax1, sharey=ax1)\nax3 = plt.subplot(1, 3, 3, sharex=ax1, sharey=ax1)\n\nax1.imshow(image, cmap='gray')\nax1.set_axis_off()\nax1.set_title('Reference image')\n\nax2.imshow(offset_image.real, cmap='gray')\nax2.set_axis_off()\nax2.set_title('Corrupted, offset image')\n\nax3.imshow(mask, cmap='gray')\nax3.set_axis_off()\nax3.set_title('Masked pixels')\n\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Solid masks are another illustrating example. In this case, we have a \nlimited view of an image and an offset image. The masks for these images \nneed not be the same. The `masked_register_translation` function will correctly identify\nwhich part of the images should be compared.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "image = data.camera()\nshift = (-22, 13)\n\nrr1, cc1 = draw.ellipse(259, 248, \n                      r_radius = 125, c_radius = 100, \n                      shape = image.shape)\n\nrr2, cc2 = draw.ellipse(300, 200, \n                        r_radius = 110, c_radius = 180, \n                        shape = image.shape)\n\nmask1 = np.zeros_like(image, dtype = np.bool)\nmask2 = np.zeros_like(image, dtype = np.bool)\nmask1[rr1, cc1] = True\nmask2[rr2, cc2] = True\n\noffset_image = ndi.shift(image, shift)\nimage *= mask1\noffset_image *= mask2\n\nprint(\"Known offset (row, col): {}\".format(shift))\n\ndetected_shift = masked_register_translation(image, offset_image, mask1, mask2)\n\nprint(\"Detected pixel offset (row, col): {}\".format(-detected_shift))\n\nfig = plt.figure(figsize=(8,3))\nax1 = plt.subplot(1, 2, 1)\nax2 = plt.subplot(1, 2, 2, sharex=ax1, sharey=ax1)\n\nax1.imshow(image, cmap='gray')\nax1.set_axis_off()\nax1.set_title('Reference image')\n\nax2.imshow(offset_image.real, cmap='gray')\nax2.set_axis_off()\nax2.set_title('Masked, offset image')\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}