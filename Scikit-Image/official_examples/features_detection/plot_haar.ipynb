{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Haar-like feature descriptor\n\n\nHaar-like features are simple digital image features that were introduced in a\nreal-time face detector [1]_. These features can be efficiently computed on any\nscale in constant time, using an integral image [1]_. After that, a small\nnumber of critical features is selected from this large set of potential\nfeatures (e.g., using AdaBoost learning algorithm as in [1]_). The following\nexample will show the mechanism to build this family of descriptors.\n\nReferences\n----------\n\n.. [1] Viola, Paul, and Michael J. Jones. \"Robust real-time face\n       detection.\" International journal of computer vision 57.2\n       (2004): 137-154.\n       http://www.merl.com/publications/docs/TR2004-043.pdf\n       :DOI:`10.1109/CVPR.2001.990517`\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom skimage.feature import haar_like_feature_coord\nfrom skimage.feature import draw_haar_like_feature\n\nprint(__doc__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Different types of Haar-like feature descriptors\n##############################################################################\n The Haar-like feature descriptors come into 5 different types as illustrated\n in the figure below. The value of the descriptor is equal to the difference\n between the sum of intensity values in the green and the red one.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "images = [np.zeros((2, 2)), np.zeros((2, 2)),\n          np.zeros((3, 3)), np.zeros((3, 3)),\n          np.zeros((2, 2))]\n\nfeature_types = ['type-2-x', 'type-2-y',\n                 'type-3-x', 'type-3-y',\n                 'type-4']\n\nfig, axs = plt.subplots(3, 2)\nfor ax, img, feat_t in zip(np.ravel(axs), images, feature_types):\n    coord, _ = haar_like_feature_coord(img.shape[0], img.shape[1], feat_t)\n    haar_feature = draw_haar_like_feature(img, 0, 0,\n                                          img.shape[0],\n                                          img.shape[1],\n                                          coord,\n                                          max_n_features=1,\n                                          random_state=0)\n    ax.imshow(haar_feature)\n    ax.set_title(feat_t)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nfig.suptitle('The different Haar-like feature descriptors')\nplt.axis('off')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The value of the descriptor is equal to the difference between the sum of the\nintensity values in the green rectangle and the red one.  the red area is\nsubtracted to the sum of the pixel intensities of the green In practice, the\nHaar-like features will be placed in all possible location of an image and a\nfeature value will be computed for each of these locations.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}